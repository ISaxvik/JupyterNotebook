{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import LabelSet\n",
    "import datetime as dt\n",
    "import panel as pn\n",
    "import concurrent.futures\n",
    "from bokeh.models import ColumnDataSource\n",
    "pn.extension()\n",
    "import panel as pn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import json \n",
    "import pandas as pd \n",
    "# from pandas.json_normalize import json_normalize #package for flattening json in pandas df\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot\n",
    "import param\n",
    "import hvplot.pandas\n",
    "from bokeh.models import GlyphRenderer, LinearAxis, LinearScale, Range1d\n",
    "from datetime import date, time\n",
    "\n",
    "pn.extension(sizing_mode='stretch_width')\n",
    "\n",
    "pn.extension('perspective')\n",
    "from cognite.client.utils import MIN_TIMESTAMP_MS, MAX_TIMESTAMP_MS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure cognite client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contact Project Administrator to get these\n",
    "TENANT_ID = \"3aa4a235-b6e2-48d5-9195-7fcf05b459b0\" # AAD using @equinor.com\n",
    "CLIENT_ID = \"3d7a85da-05ab-4675-b5f9-0c4b96a1c84b\" # CDF_ALL_USER_APPLICATION_FLOW\n",
    "CDF_CLUSTER = \"westeurope-1\"\n",
    "# -------------for DEV project-----------------\n",
    "COGNITE_PROJECT = \"equinor-dev\"\n",
    "\n",
    "# -------------for TEST project-----------------\n",
    "# COGNITE_PROJECT = \"equinor-test\"\n",
    "\n",
    "\n",
    "from cognite.client import CogniteClient\n",
    "client = CogniteClient.default_oauth_interactive(\n",
    "    project=COGNITE_PROJECT,\n",
    "    tenant_id=TENANT_ID,\n",
    "    client_id=CLIENT_ID,\n",
    "    cdf_cluster=CDF_CLUSTER,\n",
    "    client_name=\"my-cognite-python-test\", # a name to identify your session\n",
    ")\n",
    "from cognite.client.data_classes import LabelFilter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \n",
    "wellcom_dataset = \"src:015:wellcom\"\n",
    "witsml_dataset = \"src:014:witsmldata\"\n",
    "active_wellbore = \"active:wellbore\"\n",
    "\n",
    "#list wellcom wellbores that are active in WITSML\n",
    "active_wellbores = client.assets.list(data_set_external_ids = wellcom_dataset, labels=LabelFilter(contains_all=[active_wellbore]), limit=-1)\n",
    "#Get sensor data \n",
    "witsml_db  = client.time_series.list(data_set_external_ids = witsml_dataset, limit=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to pandas dataframe and flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wellbores\n",
    "pd_active_wellbores = active_wellbores.to_pandas(metadata_prefix=active_wellbores)\n",
    "\n",
    "# Sensordata\n",
    "_pd_witsml = witsml_db.to_pandas(metadata_prefix=witsml_db)\n",
    "_pd_witsml.rename(columns ={'name': 'sensorName'} , inplace = True)\n",
    "# Flatten Sensordata\n",
    "_pd_witsml_flattened = pd.concat([_pd_witsml.drop(['metadata'], axis=1), pd.json_normalize(_pd_witsml['metadata'] )], axis=1)\n",
    "\n",
    "#Limiting columns\n",
    "_pd_witsml_flattened_lim = _pd_witsml_flattened[['id', 'uidWell', 'sensorName', 'name', 'uidWellbore',  'nameWellbore','external_id',  'is_string', 'asset_id', 'is_step',\n",
    "       'description', 'security_categories', 'data_set_id', 'created_time',\n",
    "       'last_updated_time', 'type', 'commonData_dTimCreation',\n",
    "       'commonData_dTimLastChange', 'commonData_itemState',\n",
    "       'commonData_sourceName', 'creationDate', 'direction',\n",
    "       'endDateTimeIndex', 'indexCurve', 'indexType',  'nameWell',\n",
    "       'nullValue', 'objectGrowing', 'serviceCompany',\n",
    "       'startDateTimeIndex',  'uidLog',\n",
    "       'unavailable_in_source', 'witsml-server-ref', 'source',\n",
    "       'curveDescription', 'maxDateTimeIndex', 'minDateTimeIndex', 'mnemAlias',\n",
    "       'mnemonic', 'typeLogData', 'uid']]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Get name and id of wellbore\n",
    "pd_wellbores = _pd_witsml_flattened[['nameWellbore', 'uidWellbore']]\n",
    "#Get rid of duplicates\n",
    "pd_wellbores = pd_wellbores.drop_duplicates(subset=['uidWellbore'])\n",
    "#Create dictionary \n",
    "wellbore_map = {row['nameWellbore']: row['uidWellbore'] for index, row in pd_wellbores.iterrows()}\n",
    "\n",
    "#Get name and id of sensor\n",
    "pd_sensors = _pd_witsml_flattened[['sensorName', 'id', 'external_id']]\n",
    "#Get rid of duplicates\n",
    "pd_sensors = pd_sensors.drop_duplicates(subset=['id'])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pn.param.ParamMethod.loading_indicator = True\n",
    "\n",
    "# Defining the paramterised class \n",
    "class CustomDashboard(param.Parameterized):\n",
    "    \n",
    "    #Parameter for wellbore selector \n",
    "    wellbore = param.ObjectSelector(default=pd_wellbores['nameWellbore'].iloc[0], objects=list( sorted(pd_wellbores['nameWellbore'])    ))\n",
    "    #Dropdown for senors\n",
    "    sensor = param.ObjectSelector(default= _pd_witsml_flattened[_pd_witsml_flattened['nameWellbore'] == pd_wellbores['nameWellbore'].iloc[0] ]['sensorName'].iloc[0]   , objects=list( _pd_witsml_flattened[_pd_witsml_flattened['nameWellbore'] == pd_wellbores['nameWellbore'].iloc[0] ]['sensorName']) ) \n",
    "    #This is a checkbox that allows the user to view all sensor data, off by default because it's very slow\n",
    "    show_all_dates = param.Boolean(default = False)\n",
    "    #Date picker\n",
    "    date_of_operations = param.CalendarDate(default = date.today())\n",
    "        \n",
    "\n",
    "    # @param.depends('show_all_dates', watch=True)\n",
    "    # def toggle_on_change(self) :\n",
    "    #     self.plot()\n",
    "    \n",
    "\n",
    "    @param.depends('wellbore', watch=True)\n",
    "    def update_sensors(self):\n",
    "        wellbore_id = wellbore_map[self.wellbore]\n",
    "        filtered_sensors = _pd_witsml_flattened[_pd_witsml_flattened['uidWellbore'] == wellbore_id]\n",
    "        sensor_names = list(sorted(filtered_sensors['sensorName']))\n",
    "        self.param['sensor'].objects = sensor_names\n",
    "        if sensor_names:\n",
    "                self.sensor = sensor_names[0]\n",
    "        else:\n",
    "            self.sensor= None\n",
    "    \n",
    "    \n",
    "    def get_sensor_id(self):\n",
    "        wellbore_id= wellbore_map[self.wellbore]\n",
    "        sensor_data = _pd_witsml_flattened[(_pd_witsml_flattened['uidWellbore'] == wellbore_id) & (_pd_witsml_flattened['sensorName'] == self.sensor)]\n",
    "        if not sensor_data.empty:\n",
    "            return sensor_data['id'].iloc[0]\n",
    "        return None\n",
    "    \n",
    "\n",
    "    @param.depends('sensor') \n",
    "    def view(self):\n",
    "        sensor_id = self.get_sensor_id()\n",
    "        if sensor_id:\n",
    "                return pn.pane.Str(f'Selected Sensor ID: {sensor_id}')\n",
    "        return pn.pane.Str('No sensor selected')\n",
    "    \n",
    "\n",
    "\n",
    "    #Main function for plotting. Too long, should be refactored with more functions\n",
    "    @param.depends('sensor', 'date_of_operations' , 'show_all_dates')\n",
    "    def plot(self):\n",
    "\n",
    "        if self.sensor:\n",
    "\n",
    "            if(self.show_all_dates):\n",
    "                print(\"Show all dates is now checked and timestamps are set to cognite utils.\") \n",
    "                print(self.show_all_dates)\n",
    "                min_timestamps_ms =MIN_TIMESTAMP_MS\n",
    "                max_timestamps_ms = MAX_TIMESTAMP_MS\n",
    "            #If user is not viewing all the dates, then min and max should be min and max of 24 hours from the selected date.    \n",
    "            else:\n",
    "                print(\"Show all dates is set to false and timestamps are set to selected date\") \n",
    "                #Getting time stamps max and min of 24hrs of selected date\n",
    "                #Keeping datetime as well as timestamps, datetime is used later when filtering out operations data\n",
    "                min_datetime = datetime.combine(self.date_of_operations, time.min)\n",
    "                min_timestamp =min_datetime.timestamp()\n",
    "                max_datetime = datetime.combine((self.date_of_operations + timedelta(hours = 24)) , time.min)\n",
    "                max_timestamp = max_datetime.timestamp()\n",
    "                #Need to be milliseconds to work with cognite\n",
    "                min_timestamps_ms = int(min_timestamp *1000 )\n",
    "                max_timestamps_ms = int(  max_timestamp * 1000)\n",
    "                \n",
    "            \n",
    "            #Getting sensor id\n",
    "            sensor_id = int(self.get_sensor_id())\n",
    "            sensor_data = client.time_series.data.retrieve(id=sensor_id,start=min_timestamps_ms,  end=max_timestamps_ms + 1)\n",
    "            \n",
    "            #Converting sensor data to pandas\n",
    "            sensor_data_to_pd = sensor_data.to_pandas()\n",
    "            # Reindexing the sensor data\n",
    "            sensor_data_to_pd['Value'] = sensor_data_to_pd[sensor_data_to_pd.columns]\n",
    "            sensor_data_to_pd['Date'] = pd.to_datetime(sensor_data_to_pd.index)\n",
    "            #Adding a more consistant series of time stamps\n",
    "            \n",
    "            #Skips this part if  user is not viewing all date\n",
    "            if (self.show_all_dates):\n",
    "                start_date = sensor_data_to_pd['Date'].min()\n",
    "                end_date = sensor_data_to_pd['Date'].max()\n",
    "                #Finding the smallest interval to define the frequency\n",
    "            else:\n",
    "                 start_date = self.date_of_operations\n",
    "                 end_date = self.date_of_operations + timedelta(hours = 24)\n",
    "                 print(\"This should run. Have a look at start date and end date:\")\n",
    "                 print(start_date)\n",
    "                 print(end_date)\n",
    "            \n",
    "            time_diff = sensor_data_to_pd['Date'].diff().min()         \n",
    "\n",
    "\n",
    "\n",
    "            if(pd.isnull (time_diff)):\n",
    "                 print(\"There is no time diff, setting frequency to seconds\")\n",
    "                 time_diff = 'S'\n",
    "            else:\n",
    "                print(\"debug else\")\n",
    "                print(time_diff)     \n",
    "\n",
    "            #Generate timestamps\n",
    "            new_timestamps = pd.date_range(start=start_date, end=end_date, freq= time_diff)\n",
    "\n",
    "            \n",
    "            print(\"Let's check the smallest generated timestamp: \" )\n",
    "            print(new_timestamps.min)\n",
    "            \n",
    "            #Create a new DataFrame with the new timestamps\n",
    "            new_data = pd.DataFrame(new_timestamps, columns=['New_Timestamps'])\n",
    "            #Merge the new data with the original data using an outer join\n",
    "            sensor_data_to_pd = pd.merge(sensor_data_to_pd, new_data, how='outer', left_on='Date', right_on='New_Timestamps')\n",
    "            #Joining the new timestamps \n",
    "            sensor_data_to_pd.set_index('New_Timestamps')             \n",
    "\n",
    "            if not sensor_data_to_pd.empty:\n",
    "                \n",
    "                \n",
    "                max_sensor_value = sensor_data_to_pd['Value'].max()\n",
    "                min_sensor_value = sensor_data_to_pd['Value'].min()\n",
    "                center =sensor_data_to_pd['Value'].median()\n",
    "                sensor_plot = sensor_data_to_pd.hvplot.line(x='Value', y='New_Timestamps', autorange=\"y\", title=f'Sensor Data for {self.sensor}').opts(invert_yaxis=True, width = 800, height = 1000)\n",
    "                uptime_downtime_data = [\n",
    "                    {'Start': '2022-11-25 05:00:00', 'End': '2022-11-25 05:30:00', 'Status': 'Uptime'},\n",
    "                    {'Start': '2022-11-25 06:12:30', 'End': '2022-11-25 06:45:30', 'Status': 'Downtime'},\n",
    "                    {'Start': '2022-11-25 08:12:30', 'End': '2022-11-25 10:12:30', 'Status': 'Uptime'},\n",
    "\n",
    "                    {'Start': '2022-11-28 05:00:00', 'End': '2022-11-28 05:30:00', 'Status': 'Downtime'},\n",
    "                    {'Start': '2022-11-28 06:12:30', 'End': '2022-11-28 06:45:30', 'Status': 'Uptime'},\n",
    "                    {'Start': '2022-11-28 08:12:30', 'End': '2022-11-28 10:12:30', 'Status': 'Uptime'},\n",
    "                    # Add more uptime/downtime periods as needed\n",
    "                ]\n",
    "\n",
    "                \n",
    "\n",
    "                uptime_downtime_df = pd.DataFrame(uptime_downtime_data)\n",
    "\n",
    "                uptime_downtime_df['Start'] = pd.to_datetime(uptime_downtime_df['Start'])\n",
    "                uptime_downtime_df['End'] = pd.to_datetime(uptime_downtime_df['End'])\n",
    "\n",
    "\n",
    "                  \n",
    "                if(not(self.show_all_dates)):\n",
    "                    #Filtering out the uptime_downtime data to remove data that is no within the range of the selected date\n",
    "                    uptime_downtime_df = uptime_downtime_df[(uptime_downtime_df['Start'] >= min_datetime) & (uptime_downtime_df['End'] <= max_datetime)]\n",
    "                \n",
    "                labels = []\n",
    "                rects = []\n",
    "                for _, row in uptime_downtime_df.iterrows():\n",
    "                    midpoint = row['Start'] + (row['End'] - row['Start']) /2\n",
    "                    labels.append(hv.Text( center, midpoint, row['Status'] ).opts(text_font_style = 'bold', text_align = 'left') )\n",
    "                    color = 'green' if row['Status'] == 'Uptime' else 'red'\n",
    "                    rects.append(hv.Rectangles((min_sensor_value,row['Start'],max_sensor_value , row['End'])).opts(color=color, alpha=0.2))\n",
    "                \n",
    "                rects_overlay = hv.Overlay(rects)\n",
    "                labels_overlay = hv.Overlay(labels)\n",
    "        \n",
    "                return  sensor_plot *rects_overlay * labels_overlay\n",
    "        \n",
    "        \n",
    "        return pn.pane.Str('No data available for the selected sensor')\n",
    "\n",
    "    \n",
    "    #Run update sensor method to populate sensor dropdown\n",
    "    def __init__(self, **params):\n",
    "        super().__init__(**params)\n",
    "        self.update_sensors()\n",
    "        \n",
    "\n",
    "\n",
    "    def panel(self):\n",
    "        return pn.Row(\n",
    "            pn.Column(pn.Param(self.param) , self.view  , width = 300), pn.Row(self.plot)\n",
    "\n",
    "        )\n",
    "\n",
    "# Instantiate the dashboard\n",
    "dashboard = CustomDashboard()\n",
    "\n",
    "# Trigger initial sensor update\n",
    "#dashboard.update_sensors()\n",
    "\n",
    "# Display the dashboard\n",
    "dashboard.panel().show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
